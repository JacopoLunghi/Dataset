b <- length(which(dati_cor_abbandoni[,i-1]==-1))
n <- nrow(dati_cor_abbandoni)-b
print(data.frame(a,b))
p <- (a-b)/(n)
prob <- c(prob,p)
}
plot(prob,type="l",col=2,lwd=2,main="")
abline(v=1:25,col="black",lty=2)
plot(1:25,dati_cor_abbandoni[1,],type="l",ylim=c(3000,600000),col=gruppi_abbandoni[1])
for(i in 1:385) lines(1:25,dati_cor_abbandoni[i,],col=gruppi_abbandoni[i])
abline(v=1:25,col="black",lty=2)
plot(1:25,dati_cor_arrivati[1,],type="l",ylim=c(3000,600000),col=gruppi_arrivati[1])
for(i in 1:385) lines(1:25,dati_cor_arrivati[i,],col=gruppi_arrivati[i])
abline(v=1:25,col="black",lty=2)
prob <- c()
for(i in 2:25){
a <- length(which(dati_cor_abbandoni[,i]==-1))
b <- length(which(dati_cor_abbandoni[,i-1]==-1))
n <- nrow(dati_cor_abbandoni)-b
print(data.frame(a,b))
p <- (a-b)/(n)
prob <- c(prob,p)
}
plot(prob,type="l",col=2,lwd=2,main="")
abline(v=1:25,col="black",lty=2)
prob <- c()
for(i in 2:26){
a <- length(which(dati_cor_abbandoni[,i]==-1))
b <- length(which(dati_cor_abbandoni[,i-1]==-1))
n <- nrow(dati_cor_abbandoni)-b
print(data.frame(a,b))
p <- (a-b)/(n)
prob <- c(prob,p)
}
plot(prob,type="l",col=2,lwd=2,main="")
abline(v=1:25,col="black",lty=2)
prob <- c()
for(i in 2:25){
a <- length(which(dati_cor_abbandoni[,i]==-1))
b <- length(which(dati_cor_abbandoni[,i-1]==-1))
n <- nrow(dati_cor_abbandoni)-b
print(data.frame(a,b))
p <- (a-b)/(n)
prob <- c(prob,p)
}
plot(prob,type="l",col=2,lwd=2,main="")
abline(v=1:25,col="black",lty=2)
prob <- c()
for(i in 2:26){
a <- length(which(dati_cor_abbandoni[,i]==-1))
b <- length(which(dati_cor_abbandoni[,i-1]==-1))
n <- nrow(dati_cor_abbandoni)-b
print(data.frame(a,b))
p <- (a-b)/(n)
prob <- c(prob,p)
}
plot(prob,type="l",col=2,lwd=2,main="")
abline(v=1:25,col="black",lty=2)
prob <- c()
for(i in 2:3){
a <- length(which(dati_cor_abbandoni[,i]==-1))
b <- length(which(dati_cor_abbandoni[,i-1]==-1))
n <- nrow(dati_cor_abbandoni)-b
print(data.frame(a,b))
p <- (a-b)/(n)
prob <- c(prob,p)
}
plot(prob,type="l",col=2,lwd=2,main="")
abline(v=1:25,col="black",lty=2)
install.packages(c("arulesViz", "boot", "car", "caTools", "class", "cluster", "Deducer", "devtools", "e1071", "effects", "evaluate", "fields", "foreign", "gdata", "ggplot2", "googleVis", "gplots", "gtools", "Hmisc", "httpuv", "httr", "igraph", "KernSmooth", "knitr", "lattice", "lme4", "markdown", "MASS", "Matrix", "mclust", "memoise", "mgcv", "multcomp", "mvtnorm", "nlme", "nnet", "plotrix", "psych", "R.utils", "Rcpp", "reshape", "reshape2", "Rfacebook", "RGtk2", "RJSONIO", "roxygen2", "rpart", "RWeka", "RWekajars", "scales", "seriation", "shiny", "spatial", "swirl", "verification", "xtable", "yaml"))
install.packages(c("arulesViz", "boot", "car", "caTools", "class",
install.packages("twitteR")
install.packages("ROAuth")
install.packages("plyr")
install.packages("plyr")
install.packages("plyr")
install.packages("plyr")
install.packages("plyr")
library(plyr)
library(stringr)
install.packages(c("twitter","ROAuth","plyr","stringr","ggplot2"),dependencies=T)
install.packages(c("twitter", "ROAuth", "plyr", "stringr", "ggplot2"),
library("twitter","ROAuth","plyr","stringr","ggplot2")
library(plyr)
library(stringr)
library(ggplot2)
View(asylium.seeker.2012)
negative.words <- read.table("~/Documents/Documenti da applicazioni/Github/Dataset/negative-words.txt", quote="\"")
View(negative.words)
positive.words <- read.table("~/Documents/Documenti da applicazioni/Github/Dataset/positive-words.txt", quote="\"")
View(positive.words)
require(plyr)
require(string)
require(stringr)
score.sentiment = function(sentences, pos.words, neg.words, .progress="none")
score.sentiment = function(sentences, pos.words, neg.words, .progress="none")
require(plyr)
require(stringr)
require(plyr)
score.sentiment = function(sentences, pos.words, neg.words, .progress="none"){
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, pos.words, neg.words){
library(plyr)
require(stringr)
library(stringr)
score.sentiment = function(sentences, pos.words, neg.words, .progress="none"){}
score.sentiment = function(sentences, pos.words, neg.words, .progress="none")
{}
score.sentiment = function(sentences, pos.words, neg.words, .progress="none")
{
require(stringr)
require(plyr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '',sentence)
sentence = gsub('[[:cntrl:]]', '',sentence)
sentence = gsub('\\d+', '',sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
score.def = data.frame(score=scores, tex=sentences)
return(scores.df)
}
View(negative.words)
hu.liu.pos = scan('negative.words', what='character', comment.chr=';)
hu.liu.pos = scan('negative.words', what='character', comment.char=';')
hu.liu.pos = scan('negative.words', what='character', comment.char=';')
View(negative.words)
View(negative.words)
View(`d2008frame`)
hu.liu.pos = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/positive-words.txt', what='character', comment.char=';')
hu.liu.pos = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/negative-words.txt', what='character', comment.char=';')
dataset <- read.csv("/Users/sergiomac/Desktop/analisi vaccini/all_tables_2.csv")
dataset$text<-as.factor(dataset$text)
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
hu.liu.pos = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/postive-words.txt', what='character', comment.char=';')
hu.liu.pos = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/negative-words.txt', what='character', comment.char=';')
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
pos.words = c(hu.liu.pos, 'upgrade')
neg.words = c(hu.liu.neg, 'wtf', 'wait', 'waiting', 'epicfail', 'mechanical')
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
score.sentiment = function(sentences, pos.words, neg.words, .progress="none")
+ {
+ require(stringr)
+ require(plyr)
+ scores = laply(sentences, function(sentence, pos.words, neg.words) {
+ sentence = gsub('[[:punct:]]', '',sentence)
+ sentence = gsub('[[:cntrl:]]', '',sentence)
+ sentence = gsub('\\d+', '',sentence)
+ sentence = tolower(sentence)
+ word.list = str_split(sentence, '\\s+')
+ words = unlist(word.list)
+ pos.matches = match(words, pos.words)
+ neg.matches = match(words, neg.words)
+ score = sum(pos.matches) - sum(neg.matches)
+ return(score)
+ }, pos.words, neg.words, .progress=.progress )
+ score.df = data.frame(score=scores, tex=sentences)
+ return(scores.df)
+ }
score.sentiment = function(sentences, pos.words, neg.words, .progress="none"){
require(stringr)
require(plyr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '',sentence)
sentence = gsub('[[:cntrl:]]', '',sentence)
sentence = gsub('\\d+', '',sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
score.df = data.frame(score=scores, tex=sentences)
return(scores.df)
}
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
score.sentiment = function(sentences, pos.words, neg.words, .progress="none"){
require(stringr)
require(plyr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '',sentence)
sentence = gsub('[[:cntrl:]]', '',sentence)
sentence = gsub('\\d+', '',sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, tex=sentences)
return(scores.df)
}
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
path<-"/Users/sergiomac/Desktop/"
write.csv(dataset.scores,file=paste(path,"vaccini.csv",sep=""),row.names=TRUE)
score.sentiment = function(sentences, pos.words, neg.words, .progress="none"){
require(stringr)
require(plyr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '',sentence)
sentence = gsub('[[:cntrl:]]', '',sentence)
sentence = gsub('\\d+', '',sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
write.csv(dataset.scores,file=paste(path,"vaccini.csv",sep=""),row.names=TRUE)
score.sentiment = function(sentences, pos.words, neg.words, .progress="none"){
require(stringr)
require(plyr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '',sentence)
sentence = gsub('[[:cntrl:]]', '',sentence)
sentence = gsub('\\d+', '',sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
score.sentiment = function(sentences, pos.words, neg.words, .progress="none"){
+     require(stringr)
+     require(plyr)
+     scores = laply(sentences, function(sentence, pos.words, neg.words) {
+         sentence = gsub('[[:punct:]]', '',sentence)
+         sentence = gsub('[[:cntrl:]]', '',sentence)
+         sentence = gsub('\\d+', '',sentence)
+         sentence = tolower(sentence)
+         word.list = str_split(sentence, '\\s+')
+         words = unlist(word.list)
+         pos.matches = match(words, pos.words)
+         neg.matches = match(words, neg.words)
+         score = sum(pos.matches) - sum(neg.matches)
+         return(score)
+         }, pos.words, neg.words, .progress=.progress )
+     scores.df = data.frame(score=scores, text=sentences)
+     return(scores.df)
+     }
score.sentiment = function(sentences, pos.words, neg.words, .progress="none"){
require(stringr)
require(plyr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '',sentence)
sentence = gsub('[[:cntrl:]]', '',sentence)
sentence = gsub('\\d+', '',sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.patches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
write.csv(dataset.scores,file=paste(path,"vaccini.csv",sep=""),row.names=TRUE)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(stringr)
require(plyr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
write.csv(dataset.scores,file=paste(path,"vaccini.csv",sep=""),row.names=TRUE)
write.csv(dataset.scores,file=paste(path,"vaccini.csv",sep=""),row.names=TRUE)
view(dataset.scores)
View(dataset.scores)
hist(dataset.scores$score)
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
write.csv(dataset.scores,file=paste(path,"vaccini.csv",sep=""),row.names=TRUE)
View(dataset.scores)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(stringr)
require(plyr)
scores = laply(sentences, function(sentence, pos.words, neg.words) {
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
dataset.scores = score.sentiment(dataset$text, pos.words,neg.words,.progress='text')
View(dataset.scores)
The console gives the following output
pos.words = c(hu.liu.pos, 'upgrade')
neg.words = c(hu.liu.neg, 'wtf', 'wait', 'waiting', 'epicfail', 'mechanical')
hu.liu.pos = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/postive-words.txt', what='character', comment.char=';')
hu.liu.pos = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/negative-words.txt', what='character', comment.char=';')
write.csv(dataset.scores,file=paste(path,"vaccini.csv",sep=""),row.names=TRUE)
write.csv(dataset.scores,file=paste(path,"analisi_vaccini.csv",sep=""),row.names=TRUE)
neg.words = c(hu.liu.neg, 'merda', 'ladri')
write.csv(dataset.scores,file=paste(path,"analisi_vaccini.csv",sep=""),row.names=TRUE)
return(scores.df)}
}
}
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(stringr)
require(plyr)
# otteniamo un vettore di frasi. plyr gestirà una lista
# o un vettore come un "l"
# vogliamo un semplia array ("a") di punteggi, così usiamo
# "l" + "a" + "ply" = "laply"
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# puliamo le frasi con il regex integrato in R, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# convertiamo in tutto minuscolo
sentence = tolower(sentence)
# dividiamo in parole. str_split è nel pacchetto stringr
word.list = str_split(sentence, '\\s+')
# a volte una lista ha un livello di gerarchia di troppo
words = unlist(word.list)
# paragoniamo le parle dei post con le parole dei vocabolari positivo e negativo
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() ottiene la posizione del termine paragonato o NA
# noi vogliamo solo VERO/FALSO
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# e vogliamo che VERO/FALSO siano trattati come numeri 1/0 dalla funizona sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
# Carichiamo la lista delle parole
hu.liu.pos = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/negative-words.txt', what='character', comment.char=';')
# Aggiungiamo alcune parole alla lista
pos.words = c(hu.liu.pos, 'vantaggio')
neg.words = c(hu.liu.neg, 'merda', 'ladri')
# importiamo il file csv dei post
DatasetVaccini <- read.csv("/Users/sergiomac/Desktop/analisi vaccini/all_tables_2.csv")
# selezioniamo solo la colonna text
DatasetVaccini$text <- as.factor(DatasetVaccini$text)
# diamo un punteggio ai post
DatasetVaccini.scores = score.sentiment(DatasetVaccini$text, pos.words,neg.words,.progress='text')
# diamo il percorso del file analizzato
path<-"/Users/sergiomac/Desktop/"
# scriviamo il file dandogli un nome
write.csv(dataset.scores,file=paste(path,"analisi_vaccini.csv",sep=""),row.names=TRUE)
View(DatasetVaccini.scores)
hist(DatasetVaccini$score)
write.csv(dataset.scores,file=paste(path,"vaccini.csv",sep=""),row.names=TRUE)
hist(DatasetVaccini.scores$score)
hist(DatasetVaccini.scores$score)
gplot(DatasetVaccini.scores$score, xlab="Scoreof Tweets")
library(stringr)
library(ggplot2)
library(RColorBrewer)
library(ggplot2)
library(stringr)
}
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(stringr)
require(plyr)
# otteniamo un vettore di frasi. plyr gestirà una lista
# o un vettore come un "l"
# vogliamo un semplia array ("a") di punteggi, così usiamo
# "l" + "a" + "ply" = "laply"
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# puliamo le frasi con il regex integrato in R, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# convertiamo in tutto minuscolo
sentence = tolower(sentence)
# dividiamo in parole. str_split è nel pacchetto stringr
word.list = str_split(sentence, '\\s+')
# a volte una lista ha un livello di gerarchia di troppo
words = unlist(word.list)
# paragoniamo le parle dei post con le parole dei vocabolari positivo e negativo
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() ottiene la posizione del termine paragonato o NA
# noi vogliamo solo VERO/FALSO
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# e vogliamo che VERO/FALSO siano trattati come numeri 1/0 dalla funizona sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
neg.words = c(hu.liu.neg, 'merda', 'ladri')
# Carichiamo la lista delle parole
hu.liu.pos = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('/Users/sergiomac/Documents/Documenti da applicazioni/Github/Dataset/negative-words.txt', what='character', comment.char=';')
# Aggiungiamo alcune parole alla lista
pos.words = c(hu.liu.pos, 'vantaggio')
neg.words = c(hu.liu.neg, 'merda', 'ladri')
# importiamo il file csv dei post
DatasetVaccini <- read.csv("/Users/sergiomac/Desktop/analisi vaccini/all_tables_2.csv")
# selezioniamo solo la colonna text
DatasetVaccini$text <- as.factor(DatasetVaccini$text)
# diamo un punteggio ai post
DatasetVaccini.scores = score.sentiment(DatasetVaccini$text, pos.words,neg.words,.progress='text')
# diamo il percorso del file analizzato
path<-"/Users/sergiomac/Desktop/"
# scriviamo il file dandogli un nome
write.csv(dataset.scores,file=paste(path,"analisi_vaccini.csv",sep=""),row.names=TRUE)
# diamo un punteggio ai post
DatasetVaccini.scores = score.sentiment(DatasetVaccini$text, pos.words,neg.words,.progress='text')
# diamo il percorso del file analizzato
path<-"/Users/sergiomac/Desktop/"
# scriviamo il file dandogli un nome
write.csv(DatasetVaccini.scores,file=paste(path,"analisi_vaccini.csv",sep=""),row.names=TRUE)
View(DatasetVaccini.scores)
hist(DatasetVaccini.scores$score)
gplot(DatasetVaccini.scores$score, xlab="Scoreof Tweets")
qplot(DatasetVaccini.scores$score, xlab="Scoreof Tweets")
hist(DatasetVaccini.scores$score)
br.range <- seq(min(rand.data),max(rand.data),length.out=10)
br.range <- seq(min(DatasetVaccini.scores$score),max(DatasetVaccini.scores$score),length.out=10)
results <- sapply(1:ncol(DatasetVaccini.scores$score),function(x) hist(DatasetVaccini.scores$score[,x],plot=F,br=br.range)$counts)
hist(DatasetVaccini.scores$score)
colors <- brewer.pal(4, "BuPu")
pal <- colorRampPalette(colors)
pal(5)
hist(DatasetVaccini.scores$score, col = pal(30))
colors <- brewer.pal(4, "Green")
colors <- brewer.pal(4, "Greens")
pal(5)
hist(DatasetVaccini.scores$score, col = pal(30))
colors <- brewer.pal(4, "Greens")
pal <- colorRampPalette(colors)
pal(5)
hist(DatasetVaccini.scores$score, col = pal(30))
colors <- brewer.pal(10, "Greens")
colors <- brewer.pal(9, "Greens")
pal(5)
hist(DatasetVaccini.scores$score, col = pal(30))
pal(9)
hist(DatasetVaccini.scores$score, col = pal(30))
colors <- brewer.pal(4, "Greens")
pal <- colorRampPalette(colors)
pal(5)
hist(DatasetVaccini.scores$score, col = pal(30))
install_github('likert', 'jbryer')
library(devtools)
install_github('likert', 'jbryer')
Sys.setenv(PATH = paste("/opt/local/bin", Sys.getenv("PATH"), sep=":"))
install_github('likert', 'jbryer')
getOption("texi2dvi")
system("texi2dvi --version")
Sys.getenv(c("PATH", "TEX")) in R)
Sys.getenv(c("PATH", "TEX"))
install.packages(c("MASS", "Rcpp"))
install_github('likert', 'jbryer')
Sys.setenv(PATH = paste("/opt/local/bin", Sys.getenv("PATH"), sep=":"))
install_github('likert', 'jbryer')
tools::texi2dvi
